[
  {
    "instance_id": "astropy__astropy-11693",
    "patch": "diff --git a/astropy/wcs/wcsapi/fitswcs.py b/astropy/wcs/wcsapi/fitswcs.py\n--- a/astropy/wcs/wcsapi/fitswcs.py\n+++ b/astropy/wcs/wcsapi/fitswcs.py\n@@ -323,7 +323,17 @@ def pixel_to_world_values(self, *pixel_arrays):\n         return world[0] if self.world_n_dim == 1 else tuple(world)\n \n     def world_to_pixel_values(self, *world_arrays):\n-        pixel = self.all_world2pix(*world_arrays, 0)\n+        # avoid circular import\n+        from astropy.wcs.wcs import NoConvergence\n+        try:\n+            pixel = self.all_world2pix(*world_arrays, 0)\n+        except NoConvergence as e:\n+            warnings.warn(str(e))\n+            # use best_solution contained in the exception and format the same\n+            # way as all_world2pix does (using _array_converter)\n+            pixel = self._array_converter(lambda *args: e.best_solution,\n+                                         'input', *world_arrays, 0)\n+\n         return pixel[0] if self.pixel_n_dim == 1 else tuple(pixel)\n \n     @property\n"
  },
  {
    "instance_id": "astropy__astropy-12057",
    "patch": "diff --git a/astropy/nddata/nduncertainty.py b/astropy/nddata/nduncertainty.py\n--- a/astropy/nddata/nduncertainty.py\n+++ b/astropy/nddata/nduncertainty.py\n@@ -395,6 +395,40 @@ def _propagate_multiply(self, other_uncert, result_data, correlation):\n     def _propagate_divide(self, other_uncert, result_data, correlation):\n         return None\n \n+    def represent_as(self, other_uncert):\n+        \"\"\"Convert this uncertainty to a different uncertainty type.\n+\n+        Parameters\n+        ----------\n+        other_uncert : `NDUncertainty` subclass\n+            The `NDUncertainty` subclass to convert to.\n+\n+        Returns\n+        -------\n+        resulting_uncertainty : `NDUncertainty` instance\n+            An instance of ``other_uncert`` subclass containing the uncertainty\n+            converted to the new uncertainty type.\n+\n+        Raises\n+        ------\n+        TypeError\n+            If either the initial or final subclasses do not support\n+            conversion, a `TypeError` is raised.\n+        \"\"\"\n+        as_variance = getattr(self, \"_convert_to_variance\", None)\n+        if as_variance is None:\n+            raise TypeError(\n+                f\"{type(self)} does not support conversion to another \"\n+                \"uncertainty type.\"\n+            )\n+        from_variance = getattr(other_uncert, \"_convert_from_variance\", None)\n+        if from_variance is None:\n+            raise TypeError(\n+                f\"{other_uncert.__name__} does not support conversion from \"\n+                \"another uncertainty type.\"\n+            )\n+        return from_variance(as_variance())\n+\n \n class UnknownUncertainty(NDUncertainty):\n     \"\"\"This class implements any unknown uncertainty type.\n@@ -748,6 +782,17 @@ def _propagate_divide(self, other_uncert, result_data, correlation):\n     def _data_unit_to_uncertainty_unit(self, value):\n         return value\n \n+    def _convert_to_variance(self):\n+        new_array = None if self.array is None else self.array ** 2\n+        new_unit = None if self.unit is None else self.unit ** 2\n+        return VarianceUncertainty(new_array, unit=new_unit)\n+\n+    @classmethod\n+    def _convert_from_variance(cls, var_uncert):\n+        new_array = None if var_uncert.array is None else var_uncert.array ** (1 / 2)\n+        new_unit = None if var_uncert.unit is None else var_uncert.unit ** (1 / 2)\n+        return cls(new_array, unit=new_unit)\n+\n \n class VarianceUncertainty(_VariancePropagationMixin, NDUncertainty):\n     \"\"\"\n@@ -834,6 +879,13 @@ def _propagate_divide(self, other_uncert, result_data, correlation):\n     def _data_unit_to_uncertainty_unit(self, value):\n         return value ** 2\n \n+    def _convert_to_variance(self):\n+        return self\n+\n+    @classmethod\n+    def _convert_from_variance(cls, var_uncert):\n+        return var_uncert\n+\n \n def _inverse(x):\n     \"\"\"Just a simple inverse for use in the InverseVariance\"\"\"\n@@ -933,3 +985,14 @@ def _propagate_divide(self, other_uncert, result_data, correlation):\n \n     def _data_unit_to_uncertainty_unit(self, value):\n         return 1 / value ** 2\n+\n+    def _convert_to_variance(self):\n+        new_array = None if self.array is None else 1 / self.array\n+        new_unit = None if self.unit is None else 1 / self.unit\n+        return VarianceUncertainty(new_array, unit=new_unit)\n+\n+    @classmethod\n+    def _convert_from_variance(cls, var_uncert):\n+        new_array = None if var_uncert.array is None else 1 / var_uncert.array\n+        new_unit = None if var_uncert.unit is None else 1 / var_uncert.unit\n+        return cls(new_array, unit=new_unit)\n"
  },
  {
    "instance_id": "astropy__astropy-12318",
    "patch": "diff --git a/astropy/modeling/physical_models.py b/astropy/modeling/physical_models.py\n--- a/astropy/modeling/physical_models.py\n+++ b/astropy/modeling/physical_models.py\n@@ -27,7 +27,12 @@ class BlackBody(Fittable1DModel):\n         Blackbody temperature.\n \n     scale : float or `~astropy.units.Quantity` ['dimensionless']\n-        Scale factor\n+        Scale factor.  If dimensionless, input units will assumed\n+        to be in Hz and output units in (erg / (cm ** 2 * s * Hz * sr).\n+        If not dimensionless, must be equivalent to either\n+        (erg / (cm ** 2 * s * Hz * sr) or erg / (cm ** 2 * s * AA * sr),\n+        in which case the result will be returned in the requested units and\n+        the scale will be stripped of units (with the float value applied).\n \n     Notes\n     -----\n@@ -70,12 +75,40 @@ class BlackBody(Fittable1DModel):\n     scale = Parameter(default=1.0, min=0, description=\"Scale factor\")\n \n     # We allow values without units to be passed when evaluating the model, and\n-    # in this case the input x values are assumed to be frequencies in Hz.\n+    # in this case the input x values are assumed to be frequencies in Hz or wavelengths\n+    # in AA (depending on the choice of output units controlled by units on scale\n+    # and stored in self._output_units during init).\n     _input_units_allow_dimensionless = True\n \n     # We enable the spectral equivalency by default for the spectral axis\n     input_units_equivalencies = {'x': u.spectral()}\n \n+    # Store the native units returned by B_nu equation\n+    _native_units = u.erg / (u.cm ** 2 * u.s * u.Hz * u.sr)\n+\n+    # Store the base native output units.  If scale is not dimensionless, it\n+    # must be equivalent to one of these.  If equivalent to SLAM, then\n+    # input_units will expect AA for 'x', otherwise Hz.\n+    _native_output_units = {'SNU': u.erg / (u.cm ** 2 * u.s * u.Hz * u.sr),\n+                            'SLAM': u.erg / (u.cm ** 2 * u.s * u.AA * u.sr)}\n+\n+    def __init__(self, *args, **kwargs):\n+        scale = kwargs.get('scale', None)\n+\n+        # Support scale with non-dimensionless unit by stripping the unit and\n+        # storing as self._output_units.\n+        if hasattr(scale, 'unit') and not scale.unit.is_equivalent(u.dimensionless_unscaled):\n+            output_units = scale.unit\n+            if not output_units.is_equivalent(self._native_units, u.spectral_density(1*u.AA)):\n+                raise ValueError(f\"scale units not dimensionless or in surface brightness: {output_units}\")\n+\n+            kwargs['scale'] = scale.value\n+            self._output_units = output_units\n+        else:\n+            self._output_units = self._native_units\n+\n+        return super().__init__(*args, **kwargs)\n+\n     def evaluate(self, x, temperature, scale):\n         \"\"\"Evaluate the model.\n \n@@ -83,7 +116,8 @@ def evaluate(self, x, temperature, scale):\n         ----------\n         x : float, `~numpy.ndarray`, or `~astropy.units.Quantity` ['frequency']\n             Frequency at which to compute the blackbody. If no units are given,\n-            this defaults to Hz.\n+            this defaults to Hz (or AA if `scale` was initialized with units\n+            equivalent to erg / (cm ** 2 * s * AA * sr)).\n \n         temperature : float, `~numpy.ndarray`, or `~astropy.units.Quantity`\n             Temperature of the blackbody. If no units are given, this defaults\n@@ -119,30 +153,18 @@ def evaluate(self, x, temperature, scale):\n         else:\n             in_temp = temperature\n \n+        if not isinstance(x, u.Quantity):\n+            # then we assume it has input_units which depends on the\n+            # requested output units (either Hz or AA)\n+            in_x = u.Quantity(x, self.input_units['x'])\n+        else:\n+            in_x = x\n+\n         # Convert to units for calculations, also force double precision\n         with u.add_enabled_equivalencies(u.spectral() + u.temperature()):\n-            freq = u.Quantity(x, u.Hz, dtype=np.float64)\n+            freq = u.Quantity(in_x, u.Hz, dtype=np.float64)\n             temp = u.Quantity(in_temp, u.K)\n \n-        # check the units of scale and setup the output units\n-        bb_unit = u.erg / (u.cm ** 2 * u.s * u.Hz * u.sr)  # default unit\n-        # use the scale that was used at initialization for determining the units to return\n-        # to support returning the right units when fitting where units are stripped\n-        if hasattr(self.scale, \"unit\") and self.scale.unit is not None:\n-            # check that the units on scale are covertable to surface brightness units\n-            if not self.scale.unit.is_equivalent(bb_unit, u.spectral_density(x)):\n-                raise ValueError(\n-                    f\"scale units not surface brightness: {self.scale.unit}\"\n-                )\n-            # use the scale passed to get the value for scaling\n-            if hasattr(scale, \"unit\"):\n-                mult_scale = scale.value\n-            else:\n-                mult_scale = scale\n-            bb_unit = self.scale.unit\n-        else:\n-            mult_scale = scale\n-\n         # Check if input values are physically possible\n         if np.any(temp < 0):\n             raise ValueError(f\"Temperature should be positive: {temp}\")\n@@ -158,7 +180,17 @@ def evaluate(self, x, temperature, scale):\n         # Calculate blackbody flux\n         bb_nu = 2.0 * const.h * freq ** 3 / (const.c ** 2 * boltzm1) / u.sr\n \n-        y = mult_scale * bb_nu.to(bb_unit, u.spectral_density(freq))\n+        if self.scale.unit is not None:\n+            # Will be dimensionless at this point, but may not be dimensionless_unscaled\n+            if not hasattr(scale, 'unit'):\n+                # during fitting, scale will be passed without units\n+                # but we still need to convert from the input dimensionless\n+                # to dimensionless unscaled\n+                scale = scale * self.scale.unit\n+            scale = scale.to(u.dimensionless_unscaled).value\n+\n+        # NOTE: scale is already stripped of any input units\n+        y = scale * bb_nu.to(self._output_units, u.spectral_density(freq))\n \n         # If the temperature parameter has no unit, we should return a unitless\n         # value. This occurs for instance during fitting, since we drop the\n@@ -169,10 +201,13 @@ def evaluate(self, x, temperature, scale):\n \n     @property\n     def input_units(self):\n-        # The input units are those of the 'x' value, which should always be\n-        # Hz. Because we do this, and because input_units_allow_dimensionless\n-        # is set to True, dimensionless values are assumed to be in Hz.\n-        return {self.inputs[0]: u.Hz}\n+        # The input units are those of the 'x' value, which will depend on the\n+        # units compatible with the expected output units.\n+        if self._output_units.is_equivalent(self._native_output_units['SNU']):\n+            return {self.inputs[0]: u.Hz}\n+        else:\n+            # only other option is equivalent with SLAM\n+            return {self.inputs[0]: u.AA}\n \n     def _parameter_units_for_data_units(self, inputs_unit, outputs_unit):\n         return {\"temperature\": u.K}\n@@ -180,9 +215,15 @@ def _parameter_units_for_data_units(self, inputs_unit, outputs_unit):\n     @property\n     def bolometric_flux(self):\n         \"\"\"Bolometric flux.\"\"\"\n+        if self.scale.unit is not None:\n+            # Will be dimensionless at this point, but may not be dimensionless_unscaled\n+            scale = self.scale.quantity.to(u.dimensionless_unscaled)\n+        else:\n+            scale = self.scale.value\n+\n         # bolometric flux in the native units of the planck function\n         native_bolflux = (\n-            self.scale.value * const.sigma_sb * self.temperature ** 4 / np.pi\n+            scale * const.sigma_sb * self.temperature ** 4 / np.pi\n         )\n         # return in more \"astro\" units\n         return native_bolflux.to(u.erg / (u.cm ** 2 * u.s))\n"
  },
  {
    "instance_id": "astropy__astropy-12544",
    "patch": "diff --git a/astropy/io/fits/connect.py b/astropy/io/fits/connect.py\n--- a/astropy/io/fits/connect.py\n+++ b/astropy/io/fits/connect.py\n@@ -112,7 +112,8 @@ def _decode_mixins(tbl):\n \n \n def read_table_fits(input, hdu=None, astropy_native=False, memmap=False,\n-                    character_as_bytes=True, unit_parse_strict='warn'):\n+                    character_as_bytes=True, unit_parse_strict='warn',\n+                    mask_invalid=True):\n     \"\"\"\n     Read a Table object from an FITS file\n \n@@ -145,6 +146,8 @@ def read_table_fits(input, hdu=None, astropy_native=False, memmap=False,\n         fit the table in memory, you may be better off leaving memory mapping\n         off. However, if your table would not fit in memory, you should set this\n         to `True`.\n+        When set to `True` then ``mask_invalid`` is set to `False` since the\n+        masking would cause loading the full data array.\n     character_as_bytes : bool, optional\n         If `True`, string columns are stored as Numpy byte arrays (dtype ``S``)\n         and are converted on-the-fly to unicode strings when accessing\n@@ -158,6 +161,11 @@ def read_table_fits(input, hdu=None, astropy_native=False, memmap=False,\n         :class:`~astropy.units.core.UnrecognizedUnit`.\n         Values are the ones allowed by the ``parse_strict`` argument of\n         :class:`~astropy.units.core.Unit`: ``raise``, ``warn`` and ``silent``.\n+    mask_invalid : bool, optional\n+        By default the code masks NaNs in float columns and empty strings in\n+        string columns. Set this parameter to `False` to avoid the performance\n+        penalty of doing this masking step. The masking is always deactivated\n+        when using ``memmap=True`` (see above).\n \n     \"\"\"\n \n@@ -214,6 +222,11 @@ def read_table_fits(input, hdu=None, astropy_native=False, memmap=False,\n \n     else:\n \n+        if memmap:\n+            # using memmap is not compatible with masking invalid value by\n+            # default so we deactivate the masking\n+            mask_invalid = False\n+\n         hdulist = fits_open(input, character_as_bytes=character_as_bytes,\n                             memmap=memmap)\n \n@@ -222,6 +235,7 @@ def read_table_fits(input, hdu=None, astropy_native=False, memmap=False,\n                 hdulist, hdu=hdu,\n                 astropy_native=astropy_native,\n                 unit_parse_strict=unit_parse_strict,\n+                mask_invalid=mask_invalid,\n             )\n         finally:\n             hdulist.close()\n@@ -246,9 +260,9 @@ def read_table_fits(input, hdu=None, astropy_native=False, memmap=False,\n             # Return a MaskedColumn even if no elements are masked so\n             # we roundtrip better.\n             masked = True\n-        elif issubclass(coltype, np.inexact):\n+        elif mask_invalid and issubclass(coltype, np.inexact):\n             mask = np.isnan(data[col.name])\n-        elif issubclass(coltype, np.character):\n+        elif mask_invalid and issubclass(coltype, np.character):\n             mask = col.array == b''\n \n         if masked or np.any(mask):\n"
  },
  {
    "instance_id": "astropy__astropy-12825",
    "patch": "diff --git a/astropy/table/column.py b/astropy/table/column.py\n--- a/astropy/table/column.py\n+++ b/astropy/table/column.py\n@@ -340,7 +340,9 @@ class ColumnInfo(BaseColumnInfo):\n     This is required when the object is used as a mixin column within a table,\n     but can be used as a general way to store meta information.\n     \"\"\"\n-    attrs_from_parent = BaseColumnInfo.attr_names\n+    attr_names = BaseColumnInfo.attr_names | {'groups'}\n+    _attrs_no_copy = BaseColumnInfo._attrs_no_copy | {'groups'}\n+    attrs_from_parent = attr_names\n     _supports_indexing = True\n \n     def new_like(self, cols, length, metadata_conflicts='warn', name=None):\ndiff --git a/astropy/table/groups.py b/astropy/table/groups.py\n--- a/astropy/table/groups.py\n+++ b/astropy/table/groups.py\n@@ -214,7 +214,7 @@ def __len__(self):\n class ColumnGroups(BaseGroups):\n     def __init__(self, parent_column, indices=None, keys=None):\n         self.parent_column = parent_column  # parent Column\n-        self.parent_table = parent_column.parent_table\n+        self.parent_table = parent_column.info.parent_table\n         self._indices = indices\n         self._keys = keys\n \n@@ -238,7 +238,8 @@ def keys(self):\n             return self._keys\n \n     def aggregate(self, func):\n-        from .column import MaskedColumn\n+        from .column import MaskedColumn, Column\n+        from astropy.utils.compat import NUMPY_LT_1_20\n \n         i0s, i1s = self.indices[:-1], self.indices[1:]\n         par_col = self.parent_column\n@@ -248,6 +249,15 @@ def aggregate(self, func):\n         mean_case = func is np.mean\n         try:\n             if not masked and (reduceat or sum_case or mean_case):\n+                # For numpy < 1.20 there is a bug where reduceat will fail to\n+                # raise an exception for mixin columns that do not support the\n+                # operation. For details see:\n+                # https://github.com/astropy/astropy/pull/12825#issuecomment-1082412447\n+                # Instead we try the function directly with a 2-element version\n+                # of the column\n+                if NUMPY_LT_1_20 and not isinstance(par_col, Column) and len(par_col) > 0:\n+                    func(par_col[[0, 0]])\n+\n                 if mean_case:\n                     vals = np.add.reduceat(par_col, i0s) / np.diff(self.indices)\n                 else:\n@@ -256,17 +266,18 @@ def aggregate(self, func):\n                     vals = func.reduceat(par_col, i0s)\n             else:\n                 vals = np.array([func(par_col[i0: i1]) for i0, i1 in zip(i0s, i1s)])\n+            out = par_col.__class__(vals)\n         except Exception as err:\n-            raise TypeError(\"Cannot aggregate column '{}' with type '{}'\"\n-                            .format(par_col.info.name,\n-                                    par_col.info.dtype)) from err\n-\n-        out = par_col.__class__(data=vals,\n-                                name=par_col.info.name,\n-                                description=par_col.info.description,\n-                                unit=par_col.info.unit,\n-                                format=par_col.info.format,\n-                                meta=par_col.info.meta)\n+            raise TypeError(\"Cannot aggregate column '{}' with type '{}': {}\"\n+                            .format(par_col.info.name, par_col.info.dtype, err)) from err\n+\n+        out_info = out.info\n+        for attr in ('name', 'unit', 'format', 'description', 'meta'):\n+            try:\n+                setattr(out_info, attr, getattr(par_col.info, attr))\n+            except AttributeError:\n+                pass\n+\n         return out\n \n     def filter(self, func):\n@@ -354,7 +365,7 @@ def aggregate(self, func):\n                 new_col = col.take(i0s)\n             else:\n                 try:\n-                    new_col = col.groups.aggregate(func)\n+                    new_col = col.info.groups.aggregate(func)\n                 except TypeError as err:\n                     warnings.warn(str(err), AstropyUserWarning)\n                     continue\ndiff --git a/astropy/utils/data_info.py b/astropy/utils/data_info.py\n--- a/astropy/utils/data_info.py\n+++ b/astropy/utils/data_info.py\n@@ -511,7 +511,7 @@ class BaseColumnInfo(DataInfo):\n     Note that this class is defined here so that mixins can use it\n     without importing the table package.\n     \"\"\"\n-    attr_names = DataInfo.attr_names.union(['parent_table', 'indices'])\n+    attr_names = DataInfo.attr_names | {'parent_table', 'indices'}\n     _attrs_no_copy = set(['parent_table', 'indices'])\n \n     # Context for serialization.  This can be set temporarily via\n@@ -752,6 +752,15 @@ def name(self, name):\n \n         self._attrs['name'] = name\n \n+    @property\n+    def groups(self):\n+        # This implementation for mixin columns essentially matches the Column\n+        # property definition.  `groups` is a read-only property here and\n+        # depends on the parent table of the column having `groups`. This will\n+        # allow aggregating mixins as long as they support those operations.\n+        from astropy.table import groups\n+        return self._attrs.setdefault('groups', groups.ColumnGroups(self._parent))\n+\n \n class ParentDtypeInfo(MixinInfo):\n     \"\"\"Mixin that gets info.dtype from parent\"\"\"\n"
  },
  {
    "instance_id": "astropy__astropy-12842",
    "patch": "diff --git a/astropy/time/core.py b/astropy/time/core.py\n--- a/astropy/time/core.py\n+++ b/astropy/time/core.py\n@@ -34,7 +34,7 @@\n \n from astropy.extern import _strptime\n \n-__all__ = ['TimeBase', 'Time', 'TimeDelta', 'TimeInfo', 'update_leap_seconds',\n+__all__ = ['TimeBase', 'Time', 'TimeDelta', 'TimeInfo', 'TimeInfoBase', 'update_leap_seconds',\n            'TIME_SCALES', 'STANDARD_TIME_SCALES', 'TIME_DELTA_SCALES',\n            'ScaleValueError', 'OperandTypeError', 'TimeDeltaMissingUnitWarning']\n \n@@ -110,11 +110,13 @@ class _LeapSecondsCheck(enum.Enum):\n _LEAP_SECONDS_LOCK = threading.RLock()\n \n \n-class TimeInfo(MixinInfo):\n+class TimeInfoBase(MixinInfo):\n     \"\"\"\n     Container for meta information like name, description, format.  This is\n     required when the object is used as a mixin column within a table, but can\n     be used as a general way to store meta information.\n+\n+    This base class is common between TimeInfo and TimeDeltaInfo.\n     \"\"\"\n     attr_names = MixinInfo.attr_names | {'serialize_method'}\n     _supports_indexing = True\n@@ -133,6 +135,7 @@ class TimeInfo(MixinInfo):\n     @property\n     def _represent_as_dict_attrs(self):\n         method = self.serialize_method[self._serialize_context]\n+\n         if method == 'formatted_value':\n             out = ('value',)\n         elif method == 'jd1_jd2':\n@@ -182,7 +185,7 @@ def unit(self):\n     # When Time has mean, std, min, max methods:\n     # funcs = [lambda x: getattr(x, stat)() for stat_name in MixinInfo._stats])\n \n-    def _construct_from_dict_base(self, map):\n+    def _construct_from_dict(self, map):\n         if 'jd1' in map and 'jd2' in map:\n             # Initialize as JD but revert to desired format and out_subfmt (if needed)\n             format = map.pop('format')\n@@ -201,19 +204,6 @@ def _construct_from_dict_base(self, map):\n \n         return out\n \n-    def _construct_from_dict(self, map):\n-        delta_ut1_utc = map.pop('_delta_ut1_utc', None)\n-        delta_tdb_tt = map.pop('_delta_tdb_tt', None)\n-\n-        out = self._construct_from_dict_base(map)\n-\n-        if delta_ut1_utc is not None:\n-            out._delta_ut1_utc = delta_ut1_utc\n-        if delta_tdb_tt is not None:\n-            out._delta_tdb_tt = delta_tdb_tt\n-\n-        return out\n-\n     def new_like(self, cols, length, metadata_conflicts='warn', name=None):\n         \"\"\"\n         Return a new Time instance which is consistent with the input Time objects\n@@ -276,11 +266,69 @@ def new_like(self, cols, length, metadata_conflicts='warn', name=None):\n         return out\n \n \n-class TimeDeltaInfo(TimeInfo):\n-    _represent_as_dict_extra_attrs = ('format', 'scale')\n+class TimeInfo(TimeInfoBase):\n+    \"\"\"\n+    Container for meta information like name, description, format.  This is\n+    required when the object is used as a mixin column within a table, but can\n+    be used as a general way to store meta information.\n+    \"\"\"\n+    def _represent_as_dict(self, attrs=None):\n+        \"\"\"Get the values for the parent ``attrs`` and return as a dict.\n+\n+        By default, uses '_represent_as_dict_attrs'.\n+        \"\"\"\n+        map = super()._represent_as_dict(attrs=attrs)\n+\n+        # TODO: refactor these special cases into the TimeFormat classes?\n+\n+        # The datetime64 format requires special handling for ECSV (see #12840).\n+        # The `value` has numpy dtype datetime64 but this is not an allowed\n+        # datatype for ECSV. Instead convert to a string representation.\n+        if (self._serialize_context == 'ecsv'\n+                and map['format'] == 'datetime64'\n+                and 'value' in map):\n+            map['value'] = map['value'].astype('U')\n+\n+        # The datetime format is serialized as ISO with no loss of precision.\n+        if map['format'] == 'datetime' and 'value' in map:\n+            map['value'] = np.vectorize(lambda x: x.isoformat())(map['value'])\n+\n+        return map\n \n     def _construct_from_dict(self, map):\n-        return self._construct_from_dict_base(map)\n+        # See comment above. May need to convert string back to datetime64.\n+        # Note that _serialize_context is not set here so we just look for the\n+        # string value directly.\n+        if (map['format'] == 'datetime64'\n+                and 'value' in map\n+                and map['value'].dtype.kind == 'U'):\n+            map['value'] = map['value'].astype('datetime64')\n+\n+        # Convert back to datetime objects for datetime format.\n+        if map['format'] == 'datetime' and 'value' in map:\n+            from datetime import datetime\n+            map['value'] = np.vectorize(datetime.fromisoformat)(map['value'])\n+\n+        delta_ut1_utc = map.pop('_delta_ut1_utc', None)\n+        delta_tdb_tt = map.pop('_delta_tdb_tt', None)\n+\n+        out = super()._construct_from_dict(map)\n+\n+        if delta_ut1_utc is not None:\n+            out._delta_ut1_utc = delta_ut1_utc\n+        if delta_tdb_tt is not None:\n+            out._delta_tdb_tt = delta_tdb_tt\n+\n+        return out\n+\n+\n+class TimeDeltaInfo(TimeInfoBase):\n+    \"\"\"\n+    Container for meta information like name, description, format.  This is\n+    required when the object is used as a mixin column within a table, but can\n+    be used as a general way to store meta information.\n+    \"\"\"\n+    _represent_as_dict_extra_attrs = ('format', 'scale')\n \n     def new_like(self, cols, length, metadata_conflicts='warn', name=None):\n         \"\"\"\n@@ -1815,7 +1863,7 @@ def earth_rotation_angle(self, longitude=None):\n         and is rigorously corrected for polar motion.\n         (except when ``longitude='tio'``).\n \n-        \"\"\"\n+        \"\"\"  # noqa\n         if isinstance(longitude, str) and longitude == 'tio':\n             longitude = 0\n             include_tio = False\n@@ -1877,7 +1925,7 @@ def sidereal_time(self, kind, longitude=None, model=None):\n         the equator of the Celestial Intermediate Pole (CIP) and is rigorously\n         corrected for polar motion (except when ``longitude='tio'`` or ``'greenwich'``).\n \n-        \"\"\"  # docstring is formatted below\n+        \"\"\"  # noqa (docstring is formatted below)\n \n         if kind.lower() not in SIDEREAL_TIME_MODELS.keys():\n             raise ValueError('The kind of sidereal time has to be {}'.format(\n@@ -1929,7 +1977,7 @@ def _sid_time_or_earth_rot_ang(self, longitude, function, scales, include_tio=Tr\n         `~astropy.coordinates.Longitude`\n             Local sidereal time or Earth rotation angle, with units of hourangle.\n \n-        \"\"\"\n+        \"\"\"  # noqa\n         from astropy.coordinates import Longitude, EarthLocation\n         from astropy.coordinates.builtin_frames.utils import get_polar_motion\n         from astropy.coordinates.matrix_utilities import rotation_matrix\n@@ -1956,7 +2004,7 @@ def _sid_time_or_earth_rot_ang(self, longitude, function, scales, include_tio=Tr\n             r = (rotation_matrix(longitude, 'z')\n                  @ rotation_matrix(-yp, 'x', unit=u.radian)\n                  @ rotation_matrix(-xp, 'y', unit=u.radian)\n-                 @ rotation_matrix(theta+sp, 'z', unit=u.radian))\n+                 @ rotation_matrix(theta + sp, 'z', unit=u.radian))\n             # Solve for angle.\n             angle = np.arctan2(r[..., 0, 1], r[..., 0, 0]) << u.radian\n \n@@ -2781,7 +2829,6 @@ def __init__(self, left, right, op=None):\n def _check_leapsec():\n     global _LEAP_SECONDS_CHECK\n     if _LEAP_SECONDS_CHECK != _LeapSecondsCheck.DONE:\n-        from astropy.utils import iers\n         with _LEAP_SECONDS_LOCK:\n             # There are three ways we can get here:\n             # 1. First call (NOT_STARTED).\ndiff --git a/astropy/time/formats.py b/astropy/time/formats.py\n--- a/astropy/time/formats.py\n+++ b/astropy/time/formats.py\n@@ -1745,7 +1745,7 @@ class TimeBesselianEpoch(TimeEpochDate):\n \n     def _check_val_type(self, val1, val2):\n         \"\"\"Input value validation, typically overridden by derived classes\"\"\"\n-        if hasattr(val1, 'to') and hasattr(val1, 'unit'):\n+        if hasattr(val1, 'to') and hasattr(val1, 'unit') and val1.unit is not None:\n             raise ValueError(\"Cannot use Quantities for 'byear' format, \"\n                              \"as the interpretation would be ambiguous. \"\n                              \"Use float with Besselian year instead. \")\n"
  },
  {
    "instance_id": "astropy__astropy-12880",
    "patch": "diff --git a/astropy/io/ascii/ecsv.py b/astropy/io/ascii/ecsv.py\n--- a/astropy/io/ascii/ecsv.py\n+++ b/astropy/io/ascii/ecsv.py\n@@ -129,7 +129,9 @@ def get_cols(self, lines):\n         match = re.match(ecsv_header_re, lines[0].strip(), re.VERBOSE)\n         if not match:\n             raise core.InconsistentTableError(no_header_msg)\n-        # ecsv_version could be constructed here, but it is not currently used.\n+\n+        # Construct ecsv_version for backwards compatibility workarounds.\n+        self.ecsv_version = tuple(int(v or 0) for v in match.groups())\n \n         try:\n             header = meta.get_header_from_yaml(lines)\n@@ -173,7 +175,11 @@ def get_cols(self, lines):\n                     setattr(col, attr, header_cols[col.name][attr])\n \n             col.dtype = header_cols[col.name]['datatype']\n-            if col.dtype not in ECSV_DATATYPES:\n+            # Require col dtype to be a valid ECSV datatype. However, older versions\n+            # of astropy writing ECSV version 0.9 and earlier had inadvertently allowed\n+            # numpy datatypes like datetime64 or object or python str, which are not in the ECSV standard.\n+            # For back-compatibility with those existing older files, allow reading with no error.\n+            if col.dtype not in ECSV_DATATYPES and self.ecsv_version > (0, 9, 0):\n                 raise ValueError(f'datatype {col.dtype!r} of column {col.name!r} '\n                                  f'is not in allowed values {ECSV_DATATYPES}')\n \n"
  },
  {
    "instance_id": "astropy__astropy-12891",
    "patch": "diff --git a/astropy/units/quantity.py b/astropy/units/quantity.py\n--- a/astropy/units/quantity.py\n+++ b/astropy/units/quantity.py\n@@ -18,6 +18,7 @@\n \n # LOCAL\n from astropy import config as _config\n+from astropy.utils.compat import NUMPY_LT_1_20, NUMPY_LT_1_22\n from astropy.utils.compat.misc import override__dir__\n from astropy.utils.data_info import ParentDtypeInfo\n from astropy.utils.exceptions import AstropyDeprecationWarning, AstropyWarning\n@@ -1788,19 +1789,34 @@ def _wrap_function(self, function, *args, unit=None, out=None, **kwargs):\n     def trace(self, offset=0, axis1=0, axis2=1, dtype=None, out=None):\n         return self._wrap_function(np.trace, offset, axis1, axis2, dtype,\n                                    out=out)\n-\n-    def var(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False):\n-        return self._wrap_function(np.var, axis, dtype,\n-                                   out=out, ddof=ddof, keepdims=keepdims,\n-                                   unit=self.unit**2)\n-\n-    def std(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False):\n-        return self._wrap_function(np.std, axis, dtype, out=out, ddof=ddof,\n-                                   keepdims=keepdims)\n-\n-    def mean(self, axis=None, dtype=None, out=None, keepdims=False):\n-        return self._wrap_function(np.mean, axis, dtype, out=out,\n-                                   keepdims=keepdims)\n+    if NUMPY_LT_1_20:\n+        def var(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False):\n+            return self._wrap_function(np.var, axis, dtype,\n+                                       out=out, ddof=ddof, keepdims=keepdims,\n+                                       unit=self.unit**2)\n+    else:\n+        def var(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True):\n+            return self._wrap_function(np.var, axis, dtype,\n+                                       out=out, ddof=ddof, keepdims=keepdims, where=where,\n+                                       unit=self.unit**2)\n+\n+    if NUMPY_LT_1_20:\n+        def std(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False):\n+            return self._wrap_function(np.std, axis, dtype, out=out, ddof=ddof,\n+                                       keepdims=keepdims)\n+    else:\n+        def std(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True):\n+            return self._wrap_function(np.std, axis, dtype, out=out, ddof=ddof,\n+                                       keepdims=keepdims, where=where)\n+\n+    if NUMPY_LT_1_20:\n+        def mean(self, axis=None, dtype=None, out=None, keepdims=False):\n+            return self._wrap_function(np.mean, axis, dtype, out=out,\n+                                       keepdims=keepdims)\n+    else:\n+        def mean(self, axis=None, dtype=None, out=None, keepdims=False, *, where=True):\n+            return self._wrap_function(np.mean, axis, dtype, out=out,\n+                                       keepdims=keepdims, where=where)\n \n     def round(self, decimals=0, out=None):\n         return self._wrap_function(np.round, decimals, out=out)\n@@ -1827,9 +1843,14 @@ def diff(self, n=1, axis=-1):\n     def ediff1d(self, to_end=None, to_begin=None):\n         return self._wrap_function(np.ediff1d, to_end, to_begin)\n \n-    def nansum(self, axis=None, out=None, keepdims=False):\n-        return self._wrap_function(np.nansum, axis,\n-                                   out=out, keepdims=keepdims)\n+    if NUMPY_LT_1_22:\n+        def nansum(self, axis=None, out=None, keepdims=False):\n+            return self._wrap_function(np.nansum, axis,\n+                                       out=out, keepdims=keepdims)\n+    else:\n+        def nansum(self, axis=None, out=None, keepdims=False, *, initial=None, where=True):\n+            return self._wrap_function(np.nansum, axis,\n+                                       out=out, keepdims=keepdims, initial=initial, where=where)\n \n     def insert(self, obj, values, axis=None):\n         \"\"\"\ndiff --git a/astropy/utils/masked/core.py b/astropy/utils/masked/core.py\n--- a/astropy/utils/masked/core.py\n+++ b/astropy/utils/masked/core.py\n@@ -1043,7 +1043,7 @@ def clip(self, min=None, max=None, out=None, **kwargs):\n             np.minimum(out, dmax, out=out, where=True if mmax is None else ~mmax)\n         return masked_out\n \n-    def mean(self, axis=None, dtype=None, out=None, keepdims=False):\n+    def mean(self, axis=None, dtype=None, out=None, keepdims=False, *, where=True):\n         # Implementation based on that in numpy/core/_methods.py\n         # Cast bool, unsigned int, and int to float64 by default,\n         # and do float16 at higher precision.\n@@ -1055,38 +1055,42 @@ def mean(self, axis=None, dtype=None, out=None, keepdims=False):\n                 dtype = np.dtype('f4')\n                 is_float16_result = out is None\n \n+        where = ~self.mask & where\n+\n         result = self.sum(axis=axis, dtype=dtype, out=out,\n-                          keepdims=keepdims, where=~self.mask)\n-        n = np.add.reduce(~self.mask, axis=axis, keepdims=keepdims)\n+                          keepdims=keepdims, where=where)\n+        n = np.add.reduce(where, axis=axis, keepdims=keepdims)\n         result /= n\n         if is_float16_result:\n             result = result.astype(self.dtype)\n         return result\n \n-    def var(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False):\n+    def var(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True):\n+        where_final = ~self.mask & where\n+\n         # Simplified implementation based on that in numpy/core/_methods.py\n-        n = np.add.reduce(~self.mask, axis=axis, keepdims=keepdims)[...]\n+        n = np.add.reduce(where_final, axis=axis, keepdims=keepdims)[...]\n \n         # Cast bool, unsigned int, and int to float64 by default.\n         if dtype is None and issubclass(self.dtype.type,\n                                         (np.integer, np.bool_)):\n             dtype = np.dtype('f8')\n-        mean = self.mean(axis=axis, dtype=dtype, keepdims=True)\n+        mean = self.mean(axis=axis, dtype=dtype, keepdims=True, where=where)\n \n         x = self - mean\n         x *= x.conjugate()  # Conjugate just returns x if not complex.\n \n         result = x.sum(axis=axis, dtype=dtype, out=out,\n-                       keepdims=keepdims, where=~x.mask)\n+                       keepdims=keepdims, where=where_final)\n         n -= ddof\n         n = np.maximum(n, 0, out=n)\n         result /= n\n         result._mask |= (n == 0)\n         return result\n \n-    def std(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False):\n+    def std(self, axis=None, dtype=None, out=None, ddof=0, keepdims=False, *, where=True):\n         result = self.var(axis=axis, dtype=dtype, out=out, ddof=ddof,\n-                          keepdims=keepdims)\n+                          keepdims=keepdims, where=where)\n         return np.sqrt(result, out=result)\n \n     def __bool__(self):\n@@ -1094,13 +1098,13 @@ def __bool__(self):\n         result = super().__bool__()\n         return result and not self.mask\n \n-    def any(self, axis=None, out=None, keepdims=False):\n+    def any(self, axis=None, out=None, keepdims=False, *, where=True):\n         return np.logical_or.reduce(self, axis=axis, out=out,\n-                                    keepdims=keepdims, where=~self.mask)\n+                                    keepdims=keepdims, where=~self.mask & where)\n \n-    def all(self, axis=None, out=None, keepdims=False):\n+    def all(self, axis=None, out=None, keepdims=False, *, where=True):\n         return np.logical_and.reduce(self, axis=axis, out=out,\n-                                     keepdims=keepdims, where=~self.mask)\n+                                     keepdims=keepdims, where=~self.mask & where)\n \n     # Following overrides needed since somehow the ndarray implementation\n     # does not actually call these.\n"
  },
  {
    "instance_id": "astropy__astropy-12907",
    "patch": "diff --git a/astropy/modeling/separable.py b/astropy/modeling/separable.py\n--- a/astropy/modeling/separable.py\n+++ b/astropy/modeling/separable.py\n@@ -242,7 +242,7 @@ def _cstack(left, right):\n         cright = _coord_matrix(right, 'right', noutp)\n     else:\n         cright = np.zeros((noutp, right.shape[1]))\n-        cright[-right.shape[0]:, -right.shape[1]:] = 1\n+        cright[-right.shape[0]:, -right.shape[1]:] = right\n \n     return np.hstack([cleft, cright])\n \n"
  },
  {
    "instance_id": "astropy__astropy-12962",
    "patch": "diff --git a/astropy/nddata/ccddata.py b/astropy/nddata/ccddata.py\n--- a/astropy/nddata/ccddata.py\n+++ b/astropy/nddata/ccddata.py\n@@ -270,7 +270,8 @@ def uncertainty(self, value):\n             self._uncertainty = value\n \n     def to_hdu(self, hdu_mask='MASK', hdu_uncertainty='UNCERT',\n-               hdu_flags=None, wcs_relax=True, key_uncertainty_type='UTYPE'):\n+               hdu_flags=None, wcs_relax=True,\n+               key_uncertainty_type='UTYPE', as_image_hdu=False):\n         \"\"\"Creates an HDUList object from a CCDData object.\n \n         Parameters\n@@ -297,6 +298,11 @@ def to_hdu(self, hdu_mask='MASK', hdu_uncertainty='UNCERT',\n \n             .. versionadded:: 3.1\n \n+        as_image_hdu : bool\n+            If this option is `True`, the first item of the returned\n+            `~astropy.io.fits.HDUList` is a `~astropy.io.fits.ImageHDU`, instead\n+            of the default `~astropy.io.fits.PrimaryHDU`.\n+\n         Raises\n         ------\n         ValueError\n@@ -343,7 +349,11 @@ def to_hdu(self, hdu_mask='MASK', hdu_uncertainty='UNCERT',\n             # not header.\n             wcs_header = self.wcs.to_header(relax=wcs_relax)\n             header.extend(wcs_header, useblanks=False, update=True)\n-        hdus = [fits.PrimaryHDU(self.data, header)]\n+\n+        if as_image_hdu:\n+            hdus = [fits.ImageHDU(self.data, header)]\n+        else:\n+            hdus = [fits.PrimaryHDU(self.data, header)]\n \n         if hdu_mask and self.mask is not None:\n             # Always assuming that the mask is a np.ndarray (check that it has\n@@ -667,7 +677,8 @@ def fits_ccddata_reader(filename, hdu=0, unit=None, hdu_uncertainty='UNCERT',\n \n def fits_ccddata_writer(\n         ccd_data, filename, hdu_mask='MASK', hdu_uncertainty='UNCERT',\n-        hdu_flags=None, key_uncertainty_type='UTYPE', **kwd):\n+        hdu_flags=None, key_uncertainty_type='UTYPE', as_image_hdu=False,\n+        **kwd):\n     \"\"\"\n     Write CCDData object to FITS file.\n \n@@ -691,6 +702,11 @@ def fits_ccddata_writer(\n \n         .. versionadded:: 3.1\n \n+    as_image_hdu : bool\n+        If this option is `True`, the first item of the returned\n+        `~astropy.io.fits.HDUList` is a `~astropy.io.fits.ImageHDU`, instead of\n+        the default `~astropy.io.fits.PrimaryHDU`.\n+\n     kwd :\n         All additional keywords are passed to :py:mod:`astropy.io.fits`\n \n@@ -708,7 +724,10 @@ def fits_ccddata_writer(\n     \"\"\"\n     hdu = ccd_data.to_hdu(\n         hdu_mask=hdu_mask, hdu_uncertainty=hdu_uncertainty,\n-        key_uncertainty_type=key_uncertainty_type, hdu_flags=hdu_flags)\n+        key_uncertainty_type=key_uncertainty_type, hdu_flags=hdu_flags,\n+        as_image_hdu=as_image_hdu)\n+    if as_image_hdu:\n+        hdu.insert(0, fits.PrimaryHDU())\n     hdu.writeto(filename, **kwd)\n \n \n"
  },
  {
    "instance_id": "astropy__astropy-13032",
    "patch": "diff --git a/astropy/modeling/bounding_box.py b/astropy/modeling/bounding_box.py\n--- a/astropy/modeling/bounding_box.py\n+++ b/astropy/modeling/bounding_box.py\n@@ -694,6 +694,12 @@ def _validate_dict(self, bounding_box: dict):\n         for key, value in bounding_box.items():\n             self[key] = value\n \n+    @property\n+    def _available_input_index(self):\n+        model_input_index = [self._get_index(_input) for _input in self._model.inputs]\n+\n+        return [_input for _input in model_input_index if _input not in self._ignored]\n+\n     def _validate_sequence(self, bounding_box, order: str = None):\n         \"\"\"Validate passing tuple of tuples representation (or related) and setting them.\"\"\"\n         order = self._get_order(order)\n@@ -703,7 +709,7 @@ def _validate_sequence(self, bounding_box, order: str = None):\n             bounding_box = bounding_box[::-1]\n \n         for index, value in enumerate(bounding_box):\n-            self[index] = value\n+            self[self._available_input_index[index]] = value\n \n     @property\n     def _n_inputs(self) -> int:\n@@ -727,7 +733,7 @@ def _validate_iterable(self, bounding_box, order: str = None):\n     def _validate(self, bounding_box, order: str = None):\n         \"\"\"Validate and set any representation\"\"\"\n         if self._n_inputs == 1 and not isinstance(bounding_box, dict):\n-            self[0] = bounding_box\n+            self[self._available_input_index[0]] = bounding_box\n         else:\n             self._validate_iterable(bounding_box, order)\n \n@@ -751,7 +757,7 @@ def validate(cls, model, bounding_box,\n             order = bounding_box.order\n             if _preserve_ignore:\n                 ignored = bounding_box.ignored\n-            bounding_box = bounding_box.intervals\n+            bounding_box = bounding_box.named_intervals\n \n         new = cls({}, model, ignored=ignored, order=order)\n         new._validate(bounding_box)\n"
  },
  {
    "instance_id": "astropy__astropy-13033",
    "patch": "diff --git a/astropy/timeseries/core.py b/astropy/timeseries/core.py\n--- a/astropy/timeseries/core.py\n+++ b/astropy/timeseries/core.py\n@@ -55,6 +55,13 @@ class BaseTimeSeries(QTable):\n     _required_columns_relax = False\n \n     def _check_required_columns(self):\n+        def as_scalar_or_list_str(obj):\n+            if not hasattr(obj, \"__len__\"):\n+                return f\"'{obj}'\"\n+            elif len(obj) == 1:\n+                return f\"'{obj[0]}'\"\n+            else:\n+                return str(obj)\n \n         if not self._required_columns_enabled:\n             return\n@@ -76,9 +83,10 @@ def _check_required_columns(self):\n \n             elif self.colnames[:len(required_columns)] != required_columns:\n \n-                raise ValueError(\"{} object is invalid - expected '{}' \"\n-                                 \"as the first column{} but found '{}'\"\n-                                 .format(self.__class__.__name__, required_columns[0], plural, self.colnames[0]))\n+                raise ValueError(\"{} object is invalid - expected {} \"\n+                                 \"as the first column{} but found {}\"\n+                                 .format(self.__class__.__name__, as_scalar_or_list_str(required_columns),\n+                                            plural, as_scalar_or_list_str(self.colnames[:len(required_columns)])))\n \n             if (self._required_columns_relax\n                     and self._required_columns == self.colnames[:len(self._required_columns)]):\n"
  },
  {
    "instance_id": "astropy__astropy-13068",
    "patch": "diff --git a/astropy/time/core.py b/astropy/time/core.py\n--- a/astropy/time/core.py\n+++ b/astropy/time/core.py\n@@ -655,9 +655,6 @@ def precision(self):\n     @precision.setter\n     def precision(self, val):\n         del self.cache\n-        if not isinstance(val, int) or val < 0 or val > 9:\n-            raise ValueError('precision attribute must be an int between '\n-                             '0 and 9')\n         self._time.precision = val\n \n     @property\ndiff --git a/astropy/time/formats.py b/astropy/time/formats.py\n--- a/astropy/time/formats.py\n+++ b/astropy/time/formats.py\n@@ -230,6 +230,18 @@ def masked(self):\n     def jd2_filled(self):\n         return np.nan_to_num(self.jd2) if self.masked else self.jd2\n \n+    @property\n+    def precision(self):\n+        return self._precision\n+\n+    @precision.setter\n+    def precision(self, val):\n+        #Verify precision is 0-9 (inclusive)\n+        if not isinstance(val, int) or val < 0 or val > 9:\n+            raise ValueError('precision attribute must be an int between '\n+                             '0 and 9')\n+        self._precision = val\n+\n     @lazyproperty\n     def cache(self):\n         \"\"\"\n"
  },
  {
    "instance_id": "astropy__astropy-13073",
    "patch": "diff --git a/astropy/io/ascii/core.py b/astropy/io/ascii/core.py\n--- a/astropy/io/ascii/core.py\n+++ b/astropy/io/ascii/core.py\n@@ -1016,7 +1016,10 @@ class BaseOutputter:\n     \"\"\"Output table as a dict of column objects keyed on column name.  The\n     table data are stored as plain python lists within the column objects.\n     \"\"\"\n+    # User-defined converters which gets set in ascii.ui if a `converter` kwarg\n+    # is supplied.\n     converters = {}\n+\n     # Derived classes must define default_converters and __call__\n \n     @staticmethod\n@@ -1024,18 +1027,33 @@ def _validate_and_copy(col, converters):\n         \"\"\"Validate the format for the type converters and then copy those\n         which are valid converters for this column (i.e. converter type is\n         a subclass of col.type)\"\"\"\n+        # Allow specifying a single converter instead of a list of converters.\n+        # The input `converters` must be a ``type`` value that can init np.dtype.\n+        try:\n+            # Don't allow list-like things that dtype accepts\n+            assert type(converters) is type\n+            converters = [numpy.dtype(converters)]\n+        except (AssertionError, TypeError):\n+            pass\n+\n         converters_out = []\n         try:\n             for converter in converters:\n-                converter_func, converter_type = converter\n+                try:\n+                    converter_func, converter_type = converter\n+                except TypeError as err:\n+                    if str(err).startswith('cannot unpack'):\n+                        converter_func, converter_type = convert_numpy(converter)\n+                    else:\n+                        raise\n                 if not issubclass(converter_type, NoType):\n-                    raise ValueError()\n+                    raise ValueError('converter_type must be a subclass of NoType')\n                 if issubclass(converter_type, col.type):\n                     converters_out.append((converter_func, converter_type))\n \n-        except (ValueError, TypeError):\n+        except (ValueError, TypeError) as err:\n             raise ValueError('Error: invalid format for converters, see '\n-                             'documentation\\n{}'.format(converters))\n+                             f'documentation\\n{converters}: {err}')\n         return converters_out\n \n     def _convert_vals(self, cols):\ndiff --git a/astropy/io/ascii/docs.py b/astropy/io/ascii/docs.py\n--- a/astropy/io/ascii/docs.py\n+++ b/astropy/io/ascii/docs.py\n@@ -37,9 +37,12 @@\n         Line index for the end of data not counting comment or blank lines.\n         This value can be negative to count from the end.\n     converters : dict\n-        Dictionary of converters. Keys in the dictionary are columns names,\n-        values are converter functions. In addition to single column names\n-        you can use wildcards via `fnmatch` to select multiple columns.\n+        Dictionary of converters to specify output column dtypes. Each key in\n+        the dictionary is a column name or else a name matching pattern\n+        including wildcards. The value is either a data type such as ``int`` or\n+        ``np.float32``; a list of such types which is tried in order until a\n+        successful conversion is achieved; or a list of converter tuples (see\n+        the `~astropy.io.ascii.convert_numpy` function for details).\n     data_Splitter : `~astropy.io.ascii.BaseSplitter`\n         Splitter class to split data columns\n     header_Splitter : `~astropy.io.ascii.BaseSplitter`\n"
  },
  {
    "instance_id": "astropy__astropy-13075",
    "patch": "diff --git a/astropy/cosmology/io/__init__.py b/astropy/cosmology/io/__init__.py\n--- a/astropy/cosmology/io/__init__.py\n+++ b/astropy/cosmology/io/__init__.py\n@@ -5,4 +5,4 @@\n \"\"\"\n \n # Import to register with the I/O machinery\n-from . import cosmology, ecsv, mapping, model, row, table, yaml\n+from . import cosmology, ecsv, html, mapping, model, row, table, yaml  # noqa: F401\ndiff --git a/astropy/cosmology/io/html.py b/astropy/cosmology/io/html.py\nnew file mode 100644\n--- /dev/null\n+++ b/astropy/cosmology/io/html.py\n@@ -0,0 +1,189 @@\n+import astropy.cosmology.units as cu\r\n+import astropy.units as u\r\n+from astropy.cosmology.connect import readwrite_registry\r\n+from astropy.cosmology.core import Cosmology\r\n+from astropy.cosmology.parameter import Parameter\r\n+from astropy.table import QTable\r\n+\r\n+from .table import from_table, to_table\r\n+\r\n+# Format look-up for conversion, {original_name: new_name}\r\n+# TODO! move this information into the Parameters themselves\r\n+_FORMAT_TABLE = {\r\n+    \"H0\": \"$$H_{0}$$\",\r\n+    \"Om0\": \"$$\\\\Omega_{m,0}$$\",\r\n+    \"Ode0\": \"$$\\\\Omega_{\\\\Lambda,0}$$\",\r\n+    \"Tcmb0\": \"$$T_{0}$$\",\r\n+    \"Neff\": \"$$N_{eff}$$\",\r\n+    \"m_nu\": \"$$m_{nu}$$\",\r\n+    \"Ob0\": \"$$\\\\Omega_{b,0}$$\",\r\n+    \"w0\": \"$$w_{0}$$\",\r\n+    \"wa\": \"$$w_{a}$$\",\r\n+    \"wz\": \"$$w_{z}$$\",\r\n+    \"wp\": \"$$w_{p}$$\",\r\n+    \"zp\": \"$$z_{p}$$\",\r\n+}\r\n+\r\n+\r\n+def read_html_table(filename, index=None, *, move_to_meta=False, cosmology=None, latex_names=True, **kwargs):\r\n+    \"\"\"Read a |Cosmology| from an HTML file.\r\n+\r\n+    Parameters\r\n+    ----------\r\n+    filename : path-like or file-like\r\n+        From where to read the Cosmology.\r\n+    index : int or str or None, optional\r\n+        Needed to select the row in tables with multiple rows. ``index`` can be\r\n+        an integer for the row number or, if the table is indexed by a column,\r\n+        the value of that column. If the table is not indexed and ``index`` is a\r\n+        string, the \"name\" column is used as the indexing column.\r\n+\r\n+    move_to_meta : bool, optional keyword-only\r\n+        Whether to move keyword arguments that are not in the Cosmology class'\r\n+        signature to the Cosmology's metadata. This will only be applied if the\r\n+        Cosmology does NOT have a keyword-only argument (e.g. ``**kwargs``).\r\n+        Arguments moved to the metadata will be merged with existing metadata,\r\n+        preferring specified metadata in the case of a merge conflict (e.g. for\r\n+        ``Cosmology(meta={'key':10}, key=42)``, the ``Cosmology.meta`` will be\r\n+        ``{'key': 10}``).\r\n+    cosmology : str or |Cosmology| class or None, optional keyword-only\r\n+        The cosmology class (or string name thereof) to use when constructing\r\n+        the cosmology instance. The class also provides default parameter\r\n+        values, filling in any non-mandatory arguments missing in 'table'.\r\n+    latex_names : bool, optional keyword-only\r\n+        Whether the |Table| (might) have latex column names for the parameters\r\n+        that need to be mapped to the correct parameter name -- e.g. $$H_{0}$$\r\n+        to 'H0'. This is `True` by default, but can be turned off (set to\r\n+        `False`) if there is a known name conflict (e.g. both an 'H0' and\r\n+        '$$H_{0}$$' column) as this will raise an error. In this case, the\r\n+        correct name ('H0') is preferred.\r\n+    **kwargs : Any\r\n+        Passed to :attr:`astropy.table.QTable.read`. ``format`` is set to\r\n+        'ascii.html', regardless of input.\r\n+\r\n+    Returns\r\n+    -------\r\n+    |Cosmology| subclass instance\r\n+\r\n+    Raises\r\n+    ------\r\n+    ValueError\r\n+        If the keyword argument 'format' is given and is not \"ascii.html\".\r\n+    \"\"\"\r\n+    # Check that the format is 'ascii.html' (or not specified)\r\n+    format = kwargs.pop(\"format\", \"ascii.html\")\r\n+    if format != \"ascii.html\":\r\n+        raise ValueError(f\"format must be 'ascii.html', not {format}\")\r\n+\r\n+    # Reading is handled by `QTable`.\r\n+    with u.add_enabled_units(cu):  # (cosmology units not turned on by default)\r\n+        table = QTable.read(filename, format=\"ascii.html\", **kwargs)\r\n+\r\n+    # Need to map the table's column names to Cosmology inputs (parameter\r\n+    # names).\r\n+    # TODO! move the `latex_names` into `from_table`\r\n+    if latex_names:\r\n+        table_columns = set(table.colnames)\r\n+        for name, latex in _FORMAT_TABLE.items():\r\n+            if latex in table_columns:\r\n+                table.rename_column(latex, name)\r\n+\r\n+    # Build the cosmology from table, using the private backend.\r\n+    return from_table(table, index=index, move_to_meta=move_to_meta, cosmology=cosmology)\r\n+\r\n+\r\n+def write_html_table(cosmology, file, *, overwrite=False, cls=QTable, latex_names=False, **kwargs):\r\n+    r\"\"\"Serialize the |Cosmology| into a HTML table.\r\n+\r\n+    Parameters\r\n+    ----------\r\n+    cosmology : |Cosmology| subclass instance file : path-like or file-like\r\n+        Location to save the serialized cosmology.\r\n+    file : path-like or file-like\r\n+        Where to write the html table.\r\n+\r\n+    overwrite : bool, optional keyword-only\r\n+        Whether to overwrite the file, if it exists.\r\n+    cls : |Table| class, optional keyword-only\r\n+        Astropy |Table| (sub)class to use when writing. Default is |QTable|\r\n+        class.\r\n+    latex_names : bool, optional keyword-only\r\n+        Whether to format the parameters (column) names to latex -- e.g. 'H0' to\r\n+        $$H_{0}$$.\r\n+    **kwargs : Any\r\n+        Passed to ``cls.write``.\r\n+\r\n+    Raises\r\n+    ------\r\n+    TypeError\r\n+        If the optional keyword-argument 'cls' is not a subclass of |Table|.\r\n+    ValueError\r\n+        If the keyword argument 'format' is given and is not \"ascii.html\".\r\n+\r\n+    Notes\r\n+    -----\r\n+    A HTML file containing a Cosmology HTML table should have scripts enabling\r\n+    MathJax.\r\n+\r\n+    ::\r\n+        <script\r\n+        src=\"https://polyfill.io/v3/polyfill.min.js?features=es6\"></script>\r\n+        <script type=\"text/javascript\" id=\"MathJax-script\" async\r\n+            src=\"https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js\">\r\n+        </script>\r\n+    \"\"\"\r\n+    # Check that the format is 'ascii.html' (or not specified)\r\n+    format = kwargs.pop(\"format\", \"ascii.html\")\r\n+    if format != \"ascii.html\":\r\n+        raise ValueError(f\"format must be 'ascii.html', not {format}\")\r\n+\r\n+    # Set cosmology_in_meta as false for now since there is no metadata being kept\r\n+    table = to_table(cosmology, cls=cls, cosmology_in_meta=False)\r\n+\r\n+    cosmo_cls = type(cosmology)\r\n+    for name, col in table.columns.items():\r\n+        param = getattr(cosmo_cls, name, None)\r\n+        if not isinstance(param, Parameter) or param.unit in (None, u.one):\r\n+            continue\r\n+        # Replace column with unitless version\r\n+        table.replace_column(name, (col << param.unit).value, copy=False)\r\n+\r\n+    # TODO! move the `latex_names` into `to_table`\r\n+    if latex_names:\r\n+        new_names = [_FORMAT_TABLE.get(k, k) for k in cosmology.__parameters__]\r\n+        table.rename_columns(cosmology.__parameters__, new_names)\r\n+\r\n+    # Write HTML, using table I/O\r\n+    table.write(file, overwrite=overwrite, format=\"ascii.html\", **kwargs)\r\n+\r\n+\r\n+def html_identify(origin, filepath, fileobj, *args, **kwargs):\r\n+    \"\"\"Identify if an object uses the HTML Table format.\r\n+\r\n+    Parameters\r\n+    ----------\r\n+    origin : Any\r\n+        Not used.\r\n+    filepath : str or Any\r\n+        From where to read the Cosmology.\r\n+    fileobj : Any\r\n+        Not used.\r\n+    *args : Any\r\n+        Not used.\r\n+    **kwargs : Any\r\n+        Not used.\r\n+\r\n+    Returns\r\n+    -------\r\n+    bool\r\n+        If the filepath is a string ending with '.html'.\r\n+    \"\"\"\r\n+    return isinstance(filepath, str) and filepath.endswith(\".html\")\r\n+\r\n+\r\n+# ===================================================================\r\n+# Register\r\n+\r\n+readwrite_registry.register_reader(\"ascii.html\", Cosmology, read_html_table)\r\n+readwrite_registry.register_writer(\"ascii.html\", Cosmology, write_html_table)\r\n+readwrite_registry.register_identifier(\"ascii.html\", Cosmology, html_identify)\r\n"
  }
]